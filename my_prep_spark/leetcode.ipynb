{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c217ad45-64c9-4fde-a288-bb6ba8cf43e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark\n",
    "\n",
    "empty_df = spark.createDataFrame([], \"id INT, name STRING\")\n",
    "empty_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c3aedbb-c659-4aa5-93b9-ccc957aa94f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark import SparkConf ,SparkContext\n",
    "\n",
    "conf=SparkConf().setAppName(\"name\").setMaster(\"local[*]\")\n",
    "sc=SparkContext(conf=conf)\n",
    "\n",
    "rdd_data1=sc.parallalized([1,2,3,4,5])\n",
    "rdd_data1.toDF(\"id\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2475e3b-b0e7-43ec-ac24-2150b6385fb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "data_schema=StructType(\n",
    "\t\t\t[\n",
    "\t\t\tStructField(\"id\",IntegerType(),True),\n",
    "\t\t\tStructField(\"name\",StringType(),True),\n",
    "\t\t\tStructField(\"age\",IntegerType(),True),\n",
    "\t\t\tStructField(\"sal\",DecimalType(10,2),True)\n",
    "\t\t\t]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "597c4904-b312-4e2d-9de0-c5dd5617068e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1, \"Alice\", \"Engineering\", 85000, \"2021-01-15\"),\n",
    "    (2, \"Bob\", \"Engineering\", 95000, \"2020-03-10\"),\n",
    "    (3, \"Charlie\", \"HR\", 65000, \"2019-07-23\"),\n",
    "    (4, \"David\", \"Finance\", 72000, \"2022-11-01\"),\n",
    "    (5, \"Eva\", \"Engineering\", 99000, \"2018-05-19\"),\n",
    "    (6, \"Frank\", \"Finance\", 80000, \"2021-09-12\"),\n",
    "    (7, \"Grace\", \"HR\", 60000, \"2023-02-14\"),\n",
    "    (8, \"Helen\", \"Engineering\", 87000, \"2020-12-05\"),\n",
    "]\n",
    "\n",
    "columns = [\"emp_id\", \"name\", \"department\", \"salary\", \"hire_date\"]\n",
    "\n",
    "df_data = spark.createDataFrame(data, columns)\n",
    "df_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7991f662-3866-461f-88ea-2603887ae304",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F \n",
    "df_data.withColumn(\"new_column_upper\",F.upper(col(\"department\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce16fb36-0c90-4f16-a791-e33442b0398b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_data.select(\"emp_id\",col(\"name\"),df_data[\"department\"],df_data.salary).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e51b3bb9-ddfa-4973-82e9-76b66a3cd43b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#1. Add a new column\n",
    " df_data.withColumn(\"salary_bonus\",col(\"salary\")*1.13).show()\n",
    "\n",
    "#2. Modify an existing column\n",
    " df_data.withColumn(\"name\",concat(col(\"name\"),lit(\" K \"))).show()\n",
    "\n",
    "#3. Add derived columns\n",
    "df_data.withColumn(\"hire_date\",F.year(col(\"hire_date\"))).show()\n",
    "\n",
    "#4. Conditional logic (when otherwise)\n",
    "from pyspark.sql.functions import col, when\n",
    "df_data.withColumn(\"case_clm\",\n",
    "\t\t\twhen(\n",
    "               col(\"salary\")>=90000,\"high\"\n",
    "               ).when(\n",
    "                   ((col(\"salary\")<90000) & (col(\"salary\")>=80000)),\"mid\"\n",
    "                   )\n",
    "\t\t\t.otherwise(\"low\")\n",
    ").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bfb0116-8175-499b-9064-41a5cf816301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Renames an existing column in the DataFrame. \n",
    "df_data.withColumnRenamed(\"name\",\"first_name\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "531d0392-ea05-43ff-b72c-55949295cfc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_data.filter(col(\"salary\")>80000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4dc3510-78ba-433e-a098-63d791f6aaf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_data.filter(F.col(\"name\").like(\"%k\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8a5d85b-987b-4b16-8e56-4fbad71263b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_data.drop(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e20b56e7-14bf-4863-b954-1a709dcb2719",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_data.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e209ba8-5b1f-4fd3-990b-64f5826558e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df_data.orderBy(col(\"name\").desc()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c1f1e08-96d0-4def-aaf7-2a3cf4e0e541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# group by\n",
    "\n",
    "df_data.groupBy(\"department\").agg(count(col(\"name\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c130987-bab0-4a08-a1ab-8b1a580443b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"JoinsUnionsPractice\").getOrCreate()\n",
    "\n",
    "# Employee Data\n",
    "data_emp = [\n",
    "    (1, \"Alice\", 101, 85000),\n",
    "    (2, \"Bob\", 102, 95000),\n",
    "    (3, \"Charlie\", 103, 65000),\n",
    "    (4, \"David\", 101, 72000),\n",
    "    (5, \"Eva\", 104, 99000),\n",
    "]\n",
    "\n",
    "columns_emp = [\"emp_id\", \"name\", \"dept_id\", \"salary\"]\n",
    "\n",
    "df_emp = spark.createDataFrame(data_emp, columns_emp)\n",
    "df_emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd6d2afb-fc24-42c3-b36e-99c51ae8a281",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Department Data\n",
    "data_dept = [\n",
    "    (101, \"Engineering\"),\n",
    "    (102, \"HR\"),\n",
    "    (103, \"Finance\"),\n",
    "    (105, \"Marketing\"),\n",
    "]\n",
    "\n",
    "columns_dept = [\"dept_id\", \"dept_name\"]\n",
    "\n",
    "df_dept = spark.createDataFrame(data_dept, columns_dept)\n",
    "df_dept.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5035419e-c4dc-4700-897b-9249f68cb1c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_emp.join(df_dept,on=\"dept_id\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e3ca500-cc4d-40fd-a1ef-58a62adc5c2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "JOINS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "270deaa7-b438-40ca-964a-901badc78642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "customer_data = [(1,'manish','patna',\"30-05-2022\"),\n",
    "(2,'vikash','kolkata',\"12-03-2023\"),\n",
    "(3,'nikita','delhi',\"25-06-2023\"),\n",
    "(4,'rahul','ranchi',\"24-03-2023\"),\n",
    "(5,'mahesh','jaipur',\"22-03-2023\"),\n",
    "(6,'prantosh','kolkata',\"18-10-2022\"),\n",
    "(7,'raman','patna',\"30-12-2022\"),\n",
    "(8,'prakash','ranchi',\"24-02-2023\"),\n",
    "(9,'ragini','kolkata',\"03-03-2023\"),\n",
    "(10,'raushan','jaipur',\"05-02-2023\")]\n",
    "customer_schema=['customer_id','customer_name','address','date_of_joining']\n",
    "\n",
    "customer_df=spark.createDataFrame(customer_data,customer_schema)\n",
    "customer_df.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c7254eb-bb0e-4a42-8416-6fa61ef02dde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales_data = [(1,22,10,\"01-06-2022\"),\n",
    "(1,27,5,\"03-02-2023\"),\n",
    "(2,5,3,\"01-06-2023\"),\n",
    "(5,22,1,\"22-03-2023\"),\n",
    "(7,22,4,\"03-02-2023\"),\n",
    "(9,5,6,\"03-03-2023\"),\n",
    "(2,1,12,\"15-06-2023\"),\n",
    "(1,56,2,\"25-06-2023\"),\n",
    "(5,12,5,\"15-04-2023\"),\n",
    "(11,12,76,\"12-03-2023\")]\n",
    "sales_schema=['customer_id','product_id','quantity','date_of_purchase']\n",
    "\n",
    "sales_df=spark.createDataFrame(sales_data,sales_schema)\n",
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b02cb7e2-64c3-4d3b-8e38-79266ac65cb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "product_data = [(1, 'fanta',20),\n",
    "(2, 'dew',22),\n",
    "(5, 'sprite',40),\n",
    "(7, 'redbull',100),\n",
    "(12,'mazza',45),\n",
    "(22,'coke',27),\n",
    "(25,'limca',21),\n",
    "(27,'pepsi',14),\n",
    "(56,'sting',10)]\n",
    "product_schema=['id','name','price']\n",
    "\n",
    "product_df=spark.createDataFrame(product_data,product_schema)\n",
    "product_df.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e342767c-bc4b-456b-ab5c-629164a6bfe8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#inner join\n",
    "\n",
    "customer_df.join(sales_df,customer_df[\"customer_id\"]==sales_df[\"customer_id\"],\"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9248e130-2255-4e0e-a50c-8d549328db15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee70d2b7-c113-4e2c-8251-1f660aed1869",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "493c97ce-3d90-4c49-afee-98fbc59b938b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "626be9c4-6c4b-40b1-bc0c-ad66a5855814",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "leet_code_data = [\n",
    "    (1, 'Will', None),\n",
    "    (2, 'Jane', None),\n",
    "    (3, 'Alex', 2),\n",
    "    (4, 'Bill', None),\n",
    "    (5, 'Zack', 1),\n",
    "    (6, 'Mark', 2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa3e9e51-2ec7-41a3-83d1-68d7a572ecec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a116746-6996-465b-b6e9-5bfab0ac234c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "leet_code_shema=StructType([StructField('id',IntegerType(),True),\n",
    "                 StructField('name',StringType(),True),\n",
    "                 StructField('refer_id',IntegerType(),True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0c5fe87-2219-4bb2-8e4d-6bbcdaecdc28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "leet_code_data_1=spark.createDataFrame(leet_code_data,leet_code_shema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94f40291-e698-4e0c-b4d3-1d7ea8537a13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "leet_code_data_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08b30e70-d5a3-439e-b8db-64520c2d73bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "leet_code_data_1.filter(col(\"refer_id\").isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bf670dc-14dc-4714-b963-7c7eb942d41f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1, \"Alice\", \"Engineering\", 85000, \"2021-01-15\"),\n",
    "    (2, \"Bob\", \"Engineering\", 95000, \"2020-03-10\"),\n",
    "    (3, \"Charlie\", \"HR\", 65000, \"2019-07-23\"),\n",
    "    (4, \"David\", \"Finance\", 72000, \"2022-11-01\"),\n",
    "    (5, \"Eva\", \"Engineering\", 99000, \"2018-05-19\"),\n",
    "    (6, \"Frank\", \"Finance\", 80000, \"2021-09-12\"),\n",
    "    (7, \"Grace\", \"HR\", 60000, \"2023-02-14\"),\n",
    "    (8, \"Helen\", \"Engineering\", 87000, \"2020-12-05\"),\n",
    "]\n",
    "\n",
    "columns = [\"emp_id\", \"name\", \"department\", \"salary\", \"hire_date\"]\n",
    "\n",
    "df_data = spark.createDataFrame(data, columns)\n",
    "df_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2d2d72d-18ca-4072-b3c2-d8efc43c4e50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#- Show only employees from the Engineering department\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df_data.select(\"*\").where(col(\"department\")==\"Engineering\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8303420-84b0-4134-8adb-0cdd7d93387f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#- Select only name and salary columns.\n",
    "\n",
    "df_data.select(\"name\",\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e66c29c-0913-440e-872f-452ddc6d6404",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Count how many employees are in each department.\n",
    "\n",
    "df_data.groupby(\"department\")\\\n",
    "\t\t.agg(count(\"name\"))\\\n",
    "\t\t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12fd9bfa-66ca-4bee-b848-eba1e6477cd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find the average salary per department.\n",
    "df_data.groupby(\"department\")\\\n",
    "\t\t.agg(avg(\"salary\"))\\\n",
    "\t\t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3506a54a-96ea-4895-ae59-55cc14f1adce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter employees hired after 2020-01-01.\n",
    "df_data.select(\"name\",\"hire_date\").filter(col(\"hire_date\")>=\"2020-01-01\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b17cf38c-4b10-4a74-a1f7-e30b5e9d506f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sort employees by salary in descending order.\n",
    "df_data.sort(col(\"salary\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83bf93a3-1dd0-4d48-889d-157ef70dfdc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add a new column bonus = 10% of salary.\n",
    "df_data.withColumn(\"bonus\",round((col(\"salary\")*1.13),2)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cef38e8-d2ae-44e4-b1c9-104c78870402",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "leetcode",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
